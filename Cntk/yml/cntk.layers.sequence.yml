#YamlMime:PythonReference
api_name: []
items:
- _type: module
  children:
  - cntk.layers.sequence.Delay
  - cntk.layers.sequence.Fold
  - cntk.layers.sequence.PastValueWindow
  - cntk.layers.sequence.Recurrence
  - cntk.layers.sequence.RecurrenceFrom
  - cntk.layers.sequence.UnfoldFrom
  fullName: cntk.layers.sequence
  langs:
  - python
  module: cntk.layers.sequence
  name: sequence
  source:
    id: sequence
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 0
  summary: First / higher-order functions over sequences, like :func:`Recurrence`.
  type: Namespace
  uid: cntk.layers.sequence
- _type: function
  fullName: cntk.layers.sequence.Delay
  langs:
  - python
  module: cntk.layers.sequence
  name: Delay
  source:
    id: Delay
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 17
  summary: "Layer factory function to create a layer that delays input the input by\
    \ a given number of time steps. Negative means future. This is provided as a layer\
    \ that wraps `delay()` so that it can easily be used in a Sequential() expression.\n\
    -[ Example ]-\n>>> # create example input: one sequence with 4 tensors of shape\
    \ (3, 2)\n>>> from cntk.layers import Sequential\n>>> from cntk.layers.typing\
    \ import Tensor, Sequence\n>>> x = C.input(**Sequence[Tensor[2]])\n>>> x0 = np.reshape(np.arange(6,dtype=np.float32),(1,3,2))\n\
    >>> x0\narray([[[ 0.,  1.],\n        [ 2.,  3.],\n        [ 4.,  5.]]], dtype=float32)\n\
    >>> # trigram expansion: augment each item of the sequence with its left and right\
    \ neighbor\n>>> make_trigram = Sequential([tuple(Delay(T) for T in (-1,0,1)),\
    \  # create 3 shifted versions\n...                            splice])      \
    \                      # concatenate them\n>>> y = make_trigram(x)\n>>> y(x0)\n\
    [array([[ 2.,  3.,  0.,  1.,  0.,  0.],\n        [ 4.,  5.,  2.,  3.,  0.,  1.],\n\
    \        [ 0.,  0.,  4.,  5.,  2.,  3.]], dtype=float32)]\n>>> #    --(t-1)--\
    \  ---t---  --(t+1)--"
  syntax:
    content: Delay(T=1, initial_state=<cntk.default_options.default_override_or object
      at 0x000001E8743EED30>, name="")
    parameters:
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EED30>
      description: the number of time steps to look into the past, where negative
        values mean to look into the future, and 0 means a no-op (default 1).
      id: T
      type:
      - int
    - defaultValue: '1'
      description: tensor or scalar representing the initial value to be used when
        the input tensor is shifted in time.
      id: initial_state
    - description: the name of the Function instance in the network
      id: name
      type:
      - str, optional
    return:
      description: A function that accepts one argument (which must be a sequence)
        and returns it delayed by `T` steps
      type:
      - cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.sequence.Delay
- _type: function
  fullName: cntk.layers.sequence.Fold
  langs:
  - python
  module: cntk.layers.sequence
  name: Fold
  source:
    id: Fold
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 397
  summary: "Layer factory function to create a function that runs a step function\
    \ recurrently over an input sequence, and returns the final state. This is often\
    \ used for embeddings of sequences, e.g. in a sequence-to-sequence model.\n`Fold()`\
    \ is the same as `Recurrence()` except that only the final state is returned (whereas\
    \ `Recurrence()` returns the entire state sequence). Hence, this documentation\
    \ will only focus on the differences to `Recurrence()`, please see `Recurrence()`\
    \ for a detailed information on parameters.\nCommonly, the `folder_function` is\
    \ a recurrent block such as an LSTM. However, one can pass any binary function.\
    \ E.g. passing `plus` will sum up all items of a sequence; while `element_max`\
    \ would perform a max-pooling over all items of the sequence.\nNote: CNTK's Fold()\
    \ is similar to the fold() catamorphism known from functional programming. `go_backwards=False`\
    \ corresponds to a fold-left, and `True` to a fold-right, except that the `folder_function`\
    \ signature is always the one of fold-left.\n-[ Example ]-\n>>> from cntk.layers\
    \ import *\n>>> from cntk.layers.typing import *\n>>> # sequence classifier. Maps\
    \ a one-hot word sequence to a scalar probability value.\n>>> # The recurrence\
    \ is a Fold(), meaning only the final hidden state is produced.\n>>> # The Label()\
    \ layer allows to access the final hidden layer by name.\n>>> sequence_classifier\
    \ = Sequential([ Embedding(300),\n...                                    Fold(LSTM(500)),\n\
    ...                                    Dense(1, activation=sigmoid) ])\n>>> #\
    \ element-wise max-pooling over an input sequence\n>>> x = C.input(**Sequence[Tensor[2]])\n\
    >>> x0 = np.array([[ 1, 2 ],\n...                [ 6, 3 ],\n...              \
    \  [ 4, 2 ],\n...                [ 8, 1 ],\n...                [ 6, 0 ]])\n>>>\
    \ seq_max_pool = Fold(C.element_max)\n>>> y = seq_max_pool(x)\n>>> y(x0)\n   \
    \ array([[ 8.,   3.]], dtype=float32)\n>>> # element-wise sum over an input sequence\n\
    >>> seq_sum = Fold(C.plus)\n>>> y = seq_sum(x)\n>>> y(x0)\n    array([[ 25., \
    \  8.]], dtype=float32)"
  syntax:
    content: Fold(folder_function, go_backwards=<cntk.default_options.default_override_or
      object at 0x000001E8743EEE48>, initial_state=<cntk.default_options.default_override_or
      object at 0x000001E8743EEE80>, return_full_state=False, name="")
    parameters:
    - description: This function must have N+1 inputs and N outputs, where N is the
        number of state variables (typically 1 for GRU and plain RNNs, and 2 for LSTMs).
      id: folder_function
      type:
      - Function or equivalent Python function
    - defaultValue: ''
      description: if `True` then run the recurrence from the end of the sequence
        to the start.
      id: go_backwards
      type:
      - bool, defaults to False
    - defaultValue: 'False'
      description: the initial value for the state. This can be a constant or a learnable
        parameter. In the latter case, if the step function has more than 1 state
        variable, this parameter must be a tuple providing one initial state for every
        state variable.
      id: initial_state
      type:
      - scalar or tensor without batch dimension; or a tuple thereof
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EEE80>
      description: if `True` and the step function has more than one state variable,
        then the layer returns the final value of a all state variables (a tuple of
        sequences); whereas if not given or `False`, only the final value of the first
        of the state variables is returned to the caller.
      id: return_full_state
      type:
      - bool, defaults to False
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EEE48>
      description: the name of the Function instance in the network
      id: name
      type:
      - str, optional
    return:
      description: A function that accepts one argument (which must be a sequence)
        and performs the fold operation on it
      type:
      - Function
  type: Method
  uid: cntk.layers.sequence.Fold
- _type: function
  fullName: cntk.layers.sequence.PastValueWindow
  langs:
  - python
  module: cntk.layers.sequence
  name: PastValueWindow
  source:
    id: PastValueWindow
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 73
  summary: "Layer factory function to create a function that returns a static, maskable\
    \ view for N past steps over a sequence along the given 'axis'. It returns two\
    \ matrices: a value matrix, shape=(N,dim), and a valid window, shape=(N,1).\n\
    This is used for attention modeling. CNTK presently does not support nested dynamic\
    \ axes. Since attention models require nested axes (encoder hidden state vs. decoder\
    \ hidden state), this layer can be used to map the encoder's dynamic axis to a\
    \ static tensor axis. The static axis has a maximum length (`window_size`). To\
    \ account for shorter input sequences, this function also returns a validity mask\
    \ of the same axis dimension. Longer sequences will be truncated.\n-[ Example\
    \ ]-\n>>> # create example input: one sequence with 4 tensors of shape (3, 2)\n\
    >>> from cntk.layers import Sequential\n>>> from cntk.layers.typing import Tensor,\
    \ Sequence\n>>> x = C.input(**Sequence[Tensor[2]])\n>>> x0 = np.reshape(np.arange(6,dtype=np.float32),(1,3,2))\n\
    >>> x0\narray([[[ 0.,  1.],\n        [ 2.,  3.],\n        [ 4.,  5.]]], dtype=float32)\n\
    >>> # convert dynamic-length sequence to a static-dimension tensor\n>>> to_static_axis\
    \ = PastValueWindow(4, axis=-2)  # axis=-2 means second last\n>>> y = to_static_axis(x)\n\
    >>> value, valid = y(x0)\n>>> # 'value' contains the items from the back, padded\
    \ with 0\n>>> value\narray([[[ 4.,  5.],\n        [ 2.,  3.],\n        [ 0., \
    \ 1.],\n        [ 0.,  0.]]], dtype=float32)\n>>> # 'valid' contains a scalar\
    \ 1 for each valid item, and 0 for the padded ones\n>>> # E.g., when computing\
    \ the attention softmax, only items with a 1 should be considered.\n>>> valid\n\
    array([[[ 1.],\n        [ 1.],\n        [ 1.],\n        [ 0.]]], dtype=float32)"
  syntax:
    content: PastValueWindow(window_size, axis, go_backwards=<cntk.default_options.default_override_or
      object at 0x000001E8743EED68>, name="")
    parameters:
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EED68>
      id: window_size
    - description: maximum number of items in sequences. The *axis* will have this
        dimension.
      id: window_size
      type:
      - int
    - description: axis along which the concatenation will be performed
      id: axis
      type:
      - int or Axis, optional, keyword only
    - defaultValue: ''
      description: the name of the Function instance in the network
      id: name
      type:
      - str, optional, keyword only
    return:
      description: A function that accepts one argument, which must be a sequence.
        It returns a fixed-size window of the last `window_size` items, spliced along
        `axis`.
      type:
      - Function
  type: Method
  uid: cntk.layers.sequence.PastValueWindow
- _type: function
  fullName: cntk.layers.sequence.Recurrence
  langs:
  - python
  module: cntk.layers.sequence
  name: Recurrence
  source:
    id: Recurrence
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 280
  summary: "Layer factory function to create a function that runs a step function\
    \ recurrently over an input sequence. This implements the typical recurrent model.\n\
    The step function can be any `Function` or Python function with a signature `(h_prev,\
    \ x) -> h`, where `h_prev` is the previous state, `x` is the new data input, and\
    \ the output is the new state. All three are sequences of the same length. The\
    \ step function will be called item by item.\nStep functions can have more than\
    \ one state output, e.g. [LSTM()](cntk.layers.blocks.html.md#cntk.layers.blocks.LSTM.md).\
    \ In this case, the first N arguments are the previous state, followed by one\
    \ more argument that is the data input; and its output must be a tuple of N values.\
    \ In this case, the recurrence operation will, by default, return the first of\
    \ the state variables (in the LSTM case, the `h`), while additional state variables\
    \ are internal (like the LSTM's `c`). If all state variables should be returned,\
    \ pass `return_full_state=True`.\nTypical step functions are [LSTM()](cntk.layers.blocks.html.md#cntk.layers.blocks.LSTM.md),\
    \ [GRU()](cntk.layers.blocks.html.md#cntk.layers.blocks.GRU.md), and [RNNUnit()](cntk.layers.blocks.html.md#cntk.layers.blocks.RNNUnit.md).\
    \ However, any function with a signature as described above is admissible. For\
    \ example, a cumulative sum over a sequence can be computed as `Recurrence(plus)`,\
    \ or a GRU layer with projection could be realized as `Recurrence(GRU(500) >>\
    \ Dense(200))`; where the projection is applied to the hidden state as fed back\
    \ to the next step. `F>>G` is a short-hand for `Sequential([F, G])`.\nOptionally,\
    \ the recurrence can run backwards. This is useful for constructing bidirectional\
    \ models.\n`initial_state` must be a constant. To pass initial_state as a data\
    \ input, e.g. for a sequence-to-sequence model, use `RecurrenceFrom()` instead.\n\
    Note: `Recurrence()` is the equivalent to what in functional programming is often\
    \ called `scanl()`.\n-[ Example ]-\n>>> from cntk.layers import Sequential\n>>>\
    \ from cntk.layers.typing import Tensor, Sequence\n>>> # a recurrent LSTM layer\n\
    >>> lstm_layer = Recurrence(LSTM(500))\n>>> # a bidirectional LSTM layer\n>>>\
    \ # using function tuples to implement a bidirectional LSTM\n>>> bi_lstm_layer\
    \ = Sequential([(Recurrence(LSTM(250)),                      # first tuple entry:\
    \ forward pass\n...                              Recurrence(LSTM(250), go_backwards=True)),\
    \  # second: backward pass\n...                             splice])         \
    \                            # splice both on top of each other\n>>> bi_lstm_layer.update_signature(Sequence[Tensor[13]])\n\
    >>> bi_lstm_layer.shape   # shape reflects concatenation of both output states\n\
    (500,)\n>>> tuple(str(axis.name) for axis in bi_lstm_layer.dynamic_axes)  # (note:\
    \ str() needed only for Python 2.7)\n('defaultBatchAxis', 'defaultDynamicAxis')\n\
    >>> # cumulative sum over inputs\n>>> x = C.input(**Sequence[Tensor[2]])\n>>>\
    \ x0 = np.array([[   3,    2],\n...                [  13,   42],\n...        \
    \        [-100, +100]])\n>>> cum_sum = Recurrence(C.plus, initial_state=Constant([0,\
    \ 0.5]))\n>>> y = cum_sum(x)\n>>> y(x0)\n[array([[   3. ,    2.5],\n        [\
    \  16. ,   44.5],\n        [ -84. ,  144.5]], dtype=float32)]"
  syntax:
    content: Recurrence(step_function, go_backwards=<cntk.default_options.default_override_or
      object at 0x000001E8743EEDD8>, initial_state=<cntk.default_options.default_override_or
      object at 0x000001E8743EEE10>, return_full_state=False, name="")
    parameters:
    - description: This function must have N+1 inputs and N outputs, where N is the
        number of state variables (typically 1 for GRU and plain RNNs, and 2 for LSTMs).
      id: step_function
      type:
      - Function or equivalent Python function
    - defaultValue: ''
      description: if `True` then run the recurrence from the end of the sequence
        to the start.
      id: go_backwards
      type:
      - bool, defaults to False
    - defaultValue: 'False'
      description: the initial value for the state. This can be a constant or a learnable
        parameter. In the latter case, if the step function has more than 1 state
        variable, this parameter must be a tuple providing one initial state for every
        state variable.
      id: initial_state
      type:
      - scalar or tensor without batch dimension; or a tuple thereof
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EEE10>
      description: if `True` and the step function has more than one state variable,
        then the layer returns a all state variables (a tuple of sequences); whereas
        if not given or `False`, only the first state variable is returned to the
        caller.
      id: return_full_state
      type:
      - bool, defaults to False
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EEDD8>
      description: the name of the Function instance in the network
      id: name
      type:
      - str, optional
    return:
      description: A function that accepts one argument (which must be a sequence)
        and performs the recurrent operation on it
      type:
      - Function
  type: Method
  uid: cntk.layers.sequence.Recurrence
- _type: function
  fullName: cntk.layers.sequence.RecurrenceFrom
  langs:
  - python
  module: cntk.layers.sequence
  name: RecurrenceFrom
  source:
    id: RecurrenceFrom
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 167
  summary: 'Layer factory function to create a function that runs a cell function
    recurrently over an input sequence, with initial state. This layer is very similar
    to @cntk.layers.sequence.Recurrence, except that the initial state is data dependent,
    and thus passed to the layer function as a data input rather than as an initialization
    parameter to the factory function. This form is meant for use in sequence-to-sequence
    scenarios. This documentation only covers this case; for additional information
    on parameters, see @cntk.layers.sequence.Recurrence.

    The layer function returned by this factory function accepts the initial state
    as data argument(s). It has the signature `(initial_state, input_sequence) ->
    output_sequence`. If the step function has multiple state variables, then the
    first N parameters are the initial state variables.

    The initial state can be non-sequential data, as one would have for a plain sequence-to-sequence
    model, or sequential data. In the latter case, the last item is the initial state.

    -[ Example ]-

    >>> from cntk.layers import *

    >>> from cntk.layers.typing import *

    >>> # a plain sequence-to-sequence model in training (where label length is known)

    >>> en = C.input(**SequenceOver[Axis(''m'')][SparseTensor[20000]])  # English
    input sentence

    >>> fr = C.input(**SequenceOver[Axis(''n'')][SparseTensor[30000]])  # French target
    sentence

    >>> embed = Embedding(300)

    >>> encoder = Recurrence(LSTM(500), return_full_state=True)

    >>> decoder = RecurrenceFrom(LSTM(500))       # decoder starts from a data-dependent
    initial state, hence -From()

    >>> emit = Dense(30000)

    >>> h, c = encoder(embed(en)).outputs         # LSTM encoder has two outputs (h,
    c)

    >>> z = emit(decoder(h, c, sequence.past_value(fr)))   # decoder takes encoder
    outputs as initial state

    >>> loss = C.cross_entropy_with_softmax(z, fr)'
  syntax:
    content: RecurrenceFrom(step_function, go_backwards=<cntk.default_options.default_override_or
      object at 0x000001E8743EEDA0>, return_full_state=False, name="")
    parameters:
    - description: This function must have N+1 inputs and N outputs, where N is the
        number of state variables (typically 1 for GRU and plain RNNs, and 2 for LSTMs).
      id: step_function
      type:
      - Function or equivalent Python function
    - defaultValue: ''
      description: if `True` then run the recurrence from the end of the sequence
        to the start.
      id: go_backwards
      type:
      - bool, defaults to False
    - defaultValue: 'False'
      description: the initial value for the state. This can be a constant or a learnable
        parameter. In the latter case, if the step function has more than 1 state
        variable, this parameter must be a tuple providing one initial state for every
        state variable.
      id: initial_state
      type:
      - scalar or tensor without batch dimension; or a tuple thereof
    - defaultValue: <cntk.default_options.default_override_or object at 0x000001E8743EEDA0>
      description: if `True` and the step function has more than one state variable,
        then the layer returns a all state variables (a tuple of sequences); whereas
        if not given or `False`, only the first state variable is returned to the
        caller.
      id: return_full_state
      type:
      - bool, defaults to False
    return:
      description: A function that accepts arguments `(initial_state_1, initial_state_2,
        ..., input_sequence)`, where the number of initial state variables must match
        the step function's. The initial state can be a sequence, in which case its
        last (or first if `go_backwards`) item is used.
      type:
      - Function
  type: Method
  uid: cntk.layers.sequence.RecurrenceFrom
- _type: function
  fullName: cntk.layers.sequence.UnfoldFrom
  langs:
  - python
  module: cntk.layers.sequence
  name: UnfoldFrom
  source:
    id: UnfoldFrom
    path: \cntk\layers\sequence.py
    remote:
      branch: master
      path: \cntk\layers\sequence.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 482
  summary: 'Layer factory function to create a function that implements a recurrent
    generator. Starting with a seed state, the `UnfoldFrom()` layer repeatedly applies
    `generator_function` and emits the sequence of results. `UnfoldFrom(f)(s)` emits
    the sequence `f(s), f(f(s)), f(f(f(s))), ...`. `s` can be tuple-valued.

    A typical application is the decoder of a sequence-to-sequence model, the generator
    function `f` accepts a two-valued state, with the first being an emitted word,
    and the second being an internal recurrent state. The initial state would be a
    tuple `(w0, h0)` where `w0` represents the sentence-start symbol, and `h0` is
    a thought vector that encodes the input sequence (as obtained from a @cntk.layers.sequence.Fold
    operation).

    A variant allows the state and the emitted sequence to be different. In that case,
    `f` returns a tuple (output value, new state), and `UnfoldFrom(f)(s)` would emit
    the sequence `f(s)[0], f(f(s)[1])[0], f(f(f(s)[1])[1])[0], ...`.

    The maximum length of the output sequence is not unlimited, but determined by
    the argument to the layer function, multiplied by an optional increase factor.

    Optionally, a function can be provided to denote that the end of the sequence
    has been reached.

    Note: In the context of functional programming, the first form of this operation
    is known as the unfold() anamorphism.

    -[ Example ]-

    TO BE PROVIDED after signature changes.'
  syntax:
    content: UnfoldFrom(generator_function, until_predicate=None, length_increase=1,
      name="")
    parameters:
    - description: This function must have N inputs and a N-tuple-valued output, where
        N is the number of state variables. If the emitted value should be different
        from the state, then the function should have a tuple of N+1 outputs, where
        the first output is the value to emit, while the others are the state.
      id: generator_function
      type:
      - Function or equivalent Python function
    - defaultValue: ''
      description: A function that denotes when the last element of the unfold has
        been emitted. It takes the same number of argments as the generator, and returns
        a scalar that must be 1 for the last element of the sequence, and 0 otherwise.
        This is subject to the maximum length as determined by the input sequence
        and `length_increase`. If this parameter is not provided, the output length
        will be equal to the specified maximum length.
      id: until_predicate
      type:
      - Function or equivalent Python function
    - defaultValue: '1'
      description: the maximum number of output items is equal to the number of items
        of the *dynamic_axis_like* argument to the returned *unfold()* function, multiplied
        by this factor. For example, pass 1.5 here if the output sequence can be at
        most 50% longer than the input.
      id: length_increase
      type:
      - float, defaults to 1
    - defaultValue: None
      description: the name of the Function instance in the network
      id: name
      type:
      - str, optional
    return:
      description: A function that accepts two arguments (*initial state* and *dynamic_axis_like*),
        and performs the unfold operation on it. The *initial state* argument is the
        initial state for the recurrence. The *dynamic_axis_like* must be a sequence
        and provides a reference for the maximum length of the output sequence.
      type:
      - Function
  type: Method
  uid: cntk.layers.sequence.UnfoldFrom
references:
- fullName: cntk.layers.sequence.Delay
  isExternal: false
  name: Delay
  parent: cntk.layers.sequence
  uid: cntk.layers.sequence.Delay
- fullName: cntk.layers.sequence.Fold
  isExternal: false
  name: Fold
  parent: cntk.layers.sequence
  uid: cntk.layers.sequence.Fold
- fullName: cntk.layers.sequence.PastValueWindow
  isExternal: false
  name: PastValueWindow
  parent: cntk.layers.sequence
  uid: cntk.layers.sequence.PastValueWindow
- fullName: cntk.layers.sequence.Recurrence
  isExternal: false
  name: Recurrence
  parent: cntk.layers.sequence
  uid: cntk.layers.sequence.Recurrence
- fullName: cntk.layers.sequence.RecurrenceFrom
  isExternal: false
  name: RecurrenceFrom
  parent: cntk.layers.sequence
  uid: cntk.layers.sequence.RecurrenceFrom
- fullName: cntk.layers.sequence.UnfoldFrom
  isExternal: false
  name: UnfoldFrom
  parent: cntk.layers.sequence
  uid: cntk.layers.sequence.UnfoldFrom
